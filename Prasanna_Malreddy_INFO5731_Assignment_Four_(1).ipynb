{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MPrasanna14/prasanna_INFO5731_Fall2023/blob/main/Prasanna_Malreddy_INFO5731_Assignment_Four_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA, LSA, and BERTopic. The following information should be reported:\n",
        "\n",
        "(1) Features (text representation) used for topic modeling.\n",
        "\n",
        "(2) Top 10 clusters for topic modeling.\n",
        "\n",
        "(3) Summarize and describe the topic for each cluster.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15457837-f97f-480e-ac02-5c616d7721fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ['film', 'movie', 'just', 'like', 'character', 'time', 'characters', 'good', 'make', 'man']\n",
            "1 ['movie', 'just', 'funny', 'like', 'characters', 'scenes', 'time', 'good', 'man', 'worth']\n",
            "2 ['like', 'story', 'good', 'character', 'life', 'just', 'love', 'people', 'characters', 'time']\n",
            "3 ['like', 'man', 'movie', 'movies', 'film', 'lot', 'young', 'problems', 'head', 'hollywood']\n",
            "4 ['character', 'good', 'love', 'characters', 'plot', 'movie', 'really', 'development', 'hammer', 'role']\n",
            "5 ['character', 'just', 'like', 'carol', 'hammer', 'love', 'performance', 'especially', 'playing', 'fall']\n",
            "6 ['little', 'know', 'character', 'course', 'funny', 'director', 'don', 'man', 'world', 'didn']\n",
            "7 ['good', 'just', 'really', 'make', 'cast', 'quite', 'work', 'actors', 'feel', 'role']\n",
            "8 ['don', 'know', 'films', 'way', 'man', 'king', 'think', 'bad', 'great', 'seen']\n",
            "9 ['scenes', 'time', 'don', 'know', 'scene', 'director', 'funny', 'involving', 'final', 'action']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "df = 'MovieReview_Evaluation.csv'\n",
        "reviews_df = pd.read_csv(df)\n",
        "\n",
        "# Using TF-IDF for text representation\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(reviews_df['Review text'])\n",
        "\n",
        "# Apply LSA (using TruncatedSVD)\n",
        "lsa_model = TruncatedSVD(n_components=10, random_state=0)\n",
        "X_lsa = lsa_model.fit_transform(X_tfidf)\n",
        "\n",
        "terms = tfidf_vectorizer.get_feature_names_out()\n",
        "top_words_per_topic = {}\n",
        "for i, comp in enumerate(lsa_model.components_):\n",
        "    terms_comp = zip(terms, comp)\n",
        "    sorted_terms = sorted(terms_comp, key=lambda x: x[1], reverse=True)[:10]\n",
        "    top_words_per_topic[i] = [t[0] for t in sorted_terms]\n",
        "\n",
        "for i in top_words_per_topic:\n",
        "  print(i, top_words_per_topic[i])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topics for each cluster:\n",
        "\n",
        "General Assessment\n",
        "Customer Satisfaction\n",
        "Usability and functionality\n",
        "Physical attributes of laptop\n",
        "Purchase price and benefits\n",
        "Pre installed softwares\n",
        "Battery life\n",
        "Product satisfaction\n",
        "Customer service\n",
        "Unsatisfactory experienc"
      ],
      "metadata": {
        "id": "8spY_8Cp7g6E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features.\n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vATjQNTY8buA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2188296d-521e-4662-f24d-42687d0856d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR\n",
            "Average Accuracy 0.0032653121668048805\n",
            "Average Precision (Cross-validation) 8.893350289473874e-06\n",
            "Average Recall (Cross-validation) 0.0027218419981057847\n",
            "Average F1 Score (Cross-validation) 1.77223357871724e-05\n",
            "Average Precision  1.1855040582112002e-05\n",
            "Average Recall  0.0032653121668048805\n",
            "Average F1 Score  2.361361132862602e-05\n",
            "\n",
            "\n",
            "RF\n",
            "Average Accuracy 0.0032653121668048805\n",
            "Average Precision (Cross-validation) 0.0001640676322693764\n",
            "Average Recall (Cross-validation) 0.0015072482433106799\n",
            "Average F1 Score (Cross-validation) 0.0002939171620920711\n",
            "Average Precision  0.0003734638086314428\n",
            "Average Recall  0.0032653121668048805\n",
            "Average F1 Score  0.0006659246624520289\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = 'MovieReview_Evaluation.csv'\n",
        "reviews_df = pd.read_csv(df)\n",
        "\n",
        "# Feature extraction using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "X = tfidf_vectorizer.fit_transform(reviews_df['Review text'])\n",
        "y = reviews_df['Review text']\n",
        "\n",
        "# Defining models\n",
        "models = {\n",
        "    \"LR\": LogisticRegression(max_iter=1000, random_state=0),\n",
        "    \"RF\": RandomForestClassifier(random_state=0)\n",
        "}\n",
        "\n",
        "# Cross-validation and performance metrics\n",
        "scoring_updated = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro',\n",
        "                   'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
        "\n",
        "# Recalculate scores with updated metrics\n",
        "cv_results_updated = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_validate(model, X, y, scoring=scoring_updated, cv=5)\n",
        "    cv_results_updated[model_name] = scores\n",
        "\n",
        "# Summarize scores\n",
        "summary_scores = {}\n",
        "\n",
        "for model_name in models.keys():\n",
        "    model_scores = cv_results_updated[model_name]\n",
        "    summary_scores[model_name] = {\n",
        "        \"Average Accuracy\": np.mean(model_scores['test_accuracy']),\n",
        "        \"Average Precision (Cross-validation)\": np.mean(model_scores['test_precision_macro']),\n",
        "        \"Average Recall (Cross-validation)\": np.mean(model_scores['test_recall_macro']),\n",
        "        \"Average F1 Score (Cross-validation)\": np.mean(model_scores['test_f1_macro']),\n",
        "        \"Average Precision \": np.mean(model_scores['test_precision_weighted']),\n",
        "        \"Average Recall \": np.mean(model_scores['test_recall_weighted']),\n",
        "        \"Average F1 Score \": np.mean(model_scores['test_f1_weighted'])\n",
        "    }\n",
        "\n",
        "# summary_scores\n",
        "for i in summary_scores:\n",
        "  print(i)\n",
        "  for j in summary_scores[i]:\n",
        "    print(j, summary_scores[i][j])\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(20 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from canvas. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfvMKJjIXS5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f3ac00-64c6-4c3a-9235-5550fadda76c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error =  803869861.5929561\n",
            "Root-Mean Squared Error =  28352.598850774793\n",
            "R-Squared =  0.8951974349096488\n",
            "$ 127628.90410612979\n",
            "$ 161072.89913083884\n",
            "$ 172761.98060108643\n",
            "$ 184986.37195605497\n",
            "$ 200308.61022479733\n",
            "$ 175566.5925633529\n",
            "$ 173135.41980048126\n",
            "$ 163257.60952083374\n",
            "$ 182048.9136114101\n",
            "$ 122050.37599910742\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "train_df = 'train.csv'\n",
        "test_df = 'test.csv'\n",
        "\n",
        "train_dataset = pd.read_csv(train_df)\n",
        "test_dataset = pd.read_csv(test_df)\n",
        "\n",
        "features = train_dataset.drop(columns=['SalePrice', 'Id'])\n",
        "target = train_dataset['SalePrice']\n",
        "\n",
        "numeric_columns = features.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_columns = features.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Transformers\n",
        "numeric_transformer = SimpleImputer(strategy='mean')\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "data_preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_columns),\n",
        "        ('cat', cat_transformer, categorical_columns)\n",
        "    ])\n",
        "\n",
        "# Gradient Boosting model\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=0)\n",
        "\n",
        "pipeline = Pipeline(steps=[('preprocessor', data_preprocessor),\n",
        "                           ('gb_model', gb_model)])\n",
        "\n",
        "# Data Splitting\n",
        "features_train, features_valid, target_train, target_valid = train_test_split(features, target, train_size=0.8, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "pipeline.fit(features_train, target_train)\n",
        "\n",
        "valid_predictions = pipeline.predict(features_valid)\n",
        "\n",
        "# Evaluate model\n",
        "mean_squared_error_value = mean_squared_error(target_valid, valid_predictions)\n",
        "root_mean_squared_error_value = np.sqrt(mean_squared_error_value)\n",
        "r2_value = r2_score(target_valid, valid_predictions)\n",
        "\n",
        "print(\"Mean Squared Error = \", mean_squared_error_value)\n",
        "print(\"Root-Mean Squared Error = \", root_mean_squared_error_value)\n",
        "print(\"R-Squared = \", r2_value)\n",
        "\n",
        "# Predict on test data\n",
        "test_features = pd.read_csv(test_df).drop(columns=['Id'])\n",
        "test_predictions = pipeline.predict(test_features)\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"$\", test_predictions[i])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BbswDvnEX-k"
      },
      "source": [
        "# **Question 4: Using Pre-trained LLMs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKwKTnW1EX-k"
      },
      "source": [
        "(20 points)\n",
        "Utilize a **pre-trained Large Language Model (LLM) from the Hugging Face Repository** for your specific task using the data collected in Assignment 3. After creating an account on Hugging Face (https://huggingface.co/), choose a relevant LLM from their repository, such as GPT-3, BERT, or RoBERTa or any Meta based text analysis model. Provide a brief description of the selected LLM, including its original sources, significant parameters, and any task-specific fine-tuning if applied.\n",
        "\n",
        "Perform a detailed analysis of the LLM's performance on your task, including key metrics, strengths, and limitations. Additionally, discuss any challenges encountered during the implementation and potential strategies for improvement. This will enable a comprehensive understanding of the chosen LLM's applicability and effectiveness for the given task.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dw8kCFAnW2hA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}